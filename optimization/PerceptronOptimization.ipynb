{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Manually Optimize Perceptron Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are learning\n",
    "1. How to develop the forward inference pass for neural network models from scratch.\n",
    "2. How to optimize the weights of a Perceptron model for binary classification.\n",
    "3. How to optimize the weights of a Multilayer Perceptron model using stochastic hill climbing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize a Perceptron Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a model of a single neuron that can be used for two-class classification problems and provides the foundation for later developing much larger networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# define a binary classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, n_informative=2, n_redundant=1, random_state=1)\n",
    "# summarize the shape of the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Perceptron model has a single node that has one input weight for each column in the dataset. Each input is multiplied by its corresponding weight to give a weighted sum and a bias weight is then added, like an intercept coefficient in a regression model. This weighted sum is called the activation. Finally, the activation is interpreted and used to predict the class label, 1 for a positive activation and 0 for a negative activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer function\n",
    "def transfer(activation):\n",
    "    if activation >= 0.0:\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above transfer() function takes the activation of the model and returns a class label, class=1 for a positive or zero activation and class=0 for a negative activation. This is called a step transfer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function\n",
    "def activate(row, weights):\n",
    "    # add the bias, the last weight\n",
    "    activation = weights[-1]\n",
    "    # add the weighted input\n",
    "    for i in range(len(row)):\n",
    "        activation += weights[i] * row[i]\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will take the row of data and the weights for the model and calculate the weighted sum of the input with the addition of the bias weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model weights to predict 0 or 1 for a given row of data\n",
    "def predict_row(row, weights):\n",
    "    # activate for input\n",
    "    activation = activate(row, weights)\n",
    "    # transfer for activation\n",
    "    return transfer(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model weights to generate predictions for a dataset of rows\n",
    "def predict_dataset(X, weights):\n",
    "    yhats = list()\n",
    "    for row in X:\n",
    "        yhat = predict_row(row, weights)\n",
    "        yhats.append(yhat)\n",
    "    return yhats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import rand\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, n_informative=2, n_redundant=1, random_state=1)\n",
    "# determine the number of weights\n",
    "n_weights = X.shape[1] + 1\n",
    "# generate random weights\n",
    "weights = rand(n_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for dataset\n",
    "yhat = predict_dataset(X, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.343\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# calculate accuracy\n",
    "score = accuracy_score(y, yhat)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now optimize the weights of the dataset to achieve good accuracy on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization algorithm requires an objective function to optimize. It must take a set of weights and return a score that is to be minimized or maximized corresponding to a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function\n",
    "def objective(X, y, weights):\n",
    "    # generate predictions for dataset\n",
    "    yhat = predict_dataset(X, weights)\n",
    "    # calculate accuracy\n",
    "    score = accuracy_score(y, yhat)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stochastic hill climbing algorithm\n",
    "The algorithm will require an initial solution (e.g. random weights) and will iteratively keep making small changes to the solution and checking if it results in a better performing model. The amount of change made to the current solution is controlled by a step_size hyperparameter. This process will continue for a fixed number of iterations, also provided as a hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randn\n",
    "# hill climbing local search algorithm\n",
    "def hillclimbing(X, y, objective, solution, n_iter, step_size):\n",
    "    # evaluate the initial point\n",
    "    solution_eval = objective(X, y, solution)\n",
    "    # run the hill climb\n",
    "    for i in range(n_iter):\n",
    "        # take a step\n",
    "        candidate = solution + randn(len(solution)) * step_size\n",
    "        # evaluate candidate point\n",
    "        candidte_eval = objective(X, y, candidate)\n",
    "        # check if we should keep the new point\n",
    "        if candidte_eval >= solution_eval:\n",
    "            # store the new point\n",
    "            solution, solution_eval = candidate, candidte_eval\n",
    "            # report progress\n",
    "            print('>%d %.5f' % (i, solution_eval))\n",
    "    return [solution, solution_eval]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then call this function, passing in a set of weights as the initial solution and the training dataset as the dataset to optimize the model against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1 0.58955\n",
      ">7 0.59851\n",
      ">8 0.63881\n",
      ">10 0.68806\n",
      ">11 0.70896\n",
      ">12 0.72388\n",
      ">13 0.72388\n",
      ">16 0.77761\n",
      ">20 0.79552\n",
      ">22 0.80299\n",
      ">30 0.80896\n",
      ">31 0.81642\n",
      ">32 0.82985\n",
      ">34 0.83284\n",
      ">39 0.84328\n",
      ">41 0.84328\n",
      ">46 0.84328\n",
      ">47 0.84627\n",
      ">70 0.84776\n",
      ">75 0.84925\n",
      ">76 0.85075\n",
      ">77 0.85075\n",
      ">78 0.85373\n",
      ">94 0.85672\n",
      ">145 0.85821\n",
      ">166 0.85821\n",
      ">215 0.85821\n",
      ">265 0.85970\n",
      ">394 0.85970\n",
      ">414 0.86119\n",
      ">629 0.86119\n",
      ">708 0.86119\n",
      ">961 0.86269\n",
      "Done!\n",
      "f([ 0.0198308   0.07148138  1.0748972   0.22823332  0.3180039  -0.09307344]) = 0.862687\n"
     ]
    }
   ],
   "source": [
    "# define the total iterations\n",
    "n_iter = 1000\n",
    "# define the maximum step size\n",
    "step_size = 0.05\n",
    "# determine the number of weights\n",
    "n_weights = X.shape[1] + 1\n",
    "# define the initial solution\n",
    "solution = rand(n_weights)\n",
    "# perform the hill climbing search\n",
    "weights, score = hillclimbing(X_train, y_train, objective, solution, n_iter, step_size)\n",
    "print('Done!')\n",
    "print('f(%s) = %f' % (weights, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can evaluate the best model on the test dataset and report the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 86.36364\n"
     ]
    }
   ],
   "source": [
    "# generate predictions for the test dataset\n",
    "yhat = predict_dataset(X_test, weights)\n",
    "# calculate accuracy\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Test Accuracy: %.5f' % (score * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize a Multilayer Perceptron\n",
    "A Multilayer Perceptron (MLP) model is a neural network with one or more layers, where each layer has one or more nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp\n",
    "# transfer function\n",
    "def transfer(activation):\n",
    "    # sigmoid transfer function\n",
    "    return 1.0 / (1.0 + exp(-activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function for a network\n",
    "def predict_row(row, network):\n",
    "    inputs = row\n",
    "    # enumerate the layers in the network from input to output\n",
    "    for layer in network:\n",
    "        new_inputs = list()\n",
    "        # enumerate nodes in the layer\n",
    "        for node in layer:\n",
    "            # activate the node\n",
    "            activation = activate(inputs, node)\n",
    "            # transfer activation\n",
    "            output = transfer(activation)\n",
    "            # store output\n",
    "            new_inputs.append(output)\n",
    "        # output from this layer is input to the next layer\n",
    "        inputs = new_inputs\n",
    "    return inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model weights to generate predictions for a dataset of rows\n",
    "def predict_dataset(X, network):\n",
    "    yhats = list()\n",
    "    for row in X:\n",
    "        yhat = predict_row(row, network)\n",
    "        yhats.append(yhat)\n",
    "    return yhats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, n_informative=2, n_redundant=1, random_state=1)\n",
    "# determine the number of inputs\n",
    "n_inputs = X.shape[1]\n",
    "# one hidden layer and an output layer\n",
    "n_hidden = 10\n",
    "hidden1 = [rand(n_inputs + 1) for _ in range(n_hidden)]\n",
    "output1 = [rand(n_hidden + 1)]\n",
    "network = [hidden1, output1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for dataset\n",
    "yhat = predict_dataset(X, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round the predictions\n",
    "yhat = [round(y) for y in yhat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.499\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy\n",
    "score = accuracy_score(y, yhat)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can apply the stochastic hill climbing algorithm to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, we will develop a new function that creates a copy of the network and mutates each weight in the network while making the copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a step in the search space\n",
    "def step(network, step_size):\n",
    "    new_net = list()\n",
    "    # enumerate layers in the network\n",
    "    for layer in network:\n",
    "        new_layer = list()\n",
    "        # enumerate nodes in this layer\n",
    "        for node in layer:\n",
    "            # mutate the node\n",
    "            new_node = node.copy() + randn(len(node)) * step_size\n",
    "            # store node in layer\n",
    "            new_layer.append(new_node)\n",
    "        # store layer in network\n",
    "        new_net.append(new_layer)\n",
    "    return new_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hill climbing local search algorithm\n",
    "def hillclimbing(X, y, objective, solution, n_iter, step_size):\n",
    "    # evaluate the initial point\n",
    "    solution_eval = objective(X, y, solution)\n",
    "    # run the hill climb\n",
    "    for i in range(n_iter):\n",
    "        # take a step\n",
    "        candidate = step(solution, step_size)\n",
    "        # evaluate candidate point\n",
    "        candidte_eval = objective(X, y, candidate)\n",
    "        # check if we should keep the new point\n",
    "        if candidte_eval >= solution_eval:\n",
    "            # store the new point\n",
    "            solution, solution_eval = candidate, candidte_eval\n",
    "            # report progress\n",
    "            print('>%d %f' % (i, solution_eval))\n",
    "    return [solution, solution_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0 0.486567\n",
      ">1 0.486567\n",
      ">2 0.486567\n",
      ">3 0.486567\n",
      ">4 0.486567\n",
      ">5 0.486567\n",
      ">6 0.486567\n",
      ">7 0.486567\n",
      ">8 0.486567\n",
      ">9 0.486567\n",
      ">10 0.486567\n",
      ">11 0.486567\n",
      ">12 0.486567\n",
      ">13 0.486567\n",
      ">14 0.486567\n",
      ">15 0.486567\n",
      ">16 0.486567\n",
      ">17 0.486567\n",
      ">18 0.486567\n",
      ">19 0.486567\n",
      ">20 0.486567\n",
      ">21 0.486567\n",
      ">22 0.486567\n",
      ">23 0.486567\n",
      ">24 0.488060\n",
      ">25 0.489552\n",
      ">27 0.491045\n",
      ">28 0.495522\n",
      ">30 0.498507\n",
      ">34 0.498507\n",
      ">35 0.500000\n",
      ">41 0.501493\n",
      ">42 0.516418\n",
      ">43 0.519403\n",
      ">44 0.544776\n",
      ">50 0.546269\n",
      ">54 0.547761\n",
      ">55 0.559701\n",
      ">59 0.573134\n",
      ">60 0.600000\n",
      ">61 0.610448\n",
      ">62 0.614925\n",
      ">63 0.629851\n",
      ">67 0.647761\n",
      ">68 0.652239\n",
      ">70 0.667164\n",
      ">71 0.667164\n",
      ">74 0.689552\n",
      ">75 0.705970\n",
      ">77 0.723881\n",
      ">78 0.732836\n",
      ">81 0.737313\n",
      ">82 0.746269\n",
      ">83 0.761194\n",
      ">85 0.795522\n",
      ">141 0.798507\n",
      ">142 0.798507\n",
      ">144 0.808955\n",
      ">152 0.808955\n",
      ">158 0.814925\n",
      ">161 0.831343\n",
      ">185 0.831343\n",
      ">190 0.834328\n",
      ">196 0.838806\n",
      ">202 0.841791\n",
      ">209 0.847761\n",
      ">212 0.850746\n",
      ">228 0.852239\n",
      ">248 0.852239\n",
      ">272 0.856716\n",
      ">334 0.856716\n",
      ">378 0.856716\n",
      ">389 0.856716\n",
      ">410 0.856716\n",
      ">427 0.856716\n",
      ">457 0.856716\n",
      ">505 0.856716\n",
      ">551 0.858209\n",
      ">703 0.861194\n",
      ">707 0.862687\n",
      ">717 0.864179\n",
      ">739 0.868657\n",
      ">746 0.868657\n",
      ">748 0.873134\n",
      "Done!\n",
      "Best: 0.873134\n",
      "Test Accuracy: 84.84848\n"
     ]
    }
   ],
   "source": [
    "# stochastic hill climbing to optimize a multilayer perceptron for classification\n",
    "from math import exp\n",
    "from numpy.random import randn\n",
    "from numpy.random import rand\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# transfer function\n",
    "def transfer(activation):\n",
    "    # sigmoid transfer function\n",
    "    return 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "# activation function\n",
    "def activate(row, weights):\n",
    "    # add the bias, the last weight\n",
    "    activation = weights[-1]\n",
    "    # add the weighted input\n",
    "    for i in range(len(row)):\n",
    "        activation += weights[i] * row[i]\n",
    "    return activation\n",
    "\n",
    "# activation function for a network\n",
    "def predict_row(row, network):\n",
    "    inputs = row\n",
    "    # enumerate the layers in the network from input to output\n",
    "    for layer in network:\n",
    "        new_inputs = list()\n",
    "        # enumerate nodes in the layer\n",
    "        for node in layer:\n",
    "            # activate the node\n",
    "            activation = activate(inputs, node)\n",
    "            # transfer activation\n",
    "            output = transfer(activation)\n",
    "            # store output\n",
    "            new_inputs.append(output)\n",
    "        # output from this layer is input to the next layer\n",
    "        inputs = new_inputs\n",
    "    return inputs[0]\n",
    "\n",
    "# use model weights to generate predictions for a dataset of rows\n",
    "def predict_dataset(X, network):\n",
    "    yhats = list()\n",
    "    for row in X:\n",
    "        yhat = predict_row(row, network)\n",
    "        yhats.append(yhat)\n",
    "    return yhats\n",
    "\n",
    "# objective function\n",
    "def objective(X, y, network):\n",
    "    # generate predictions for dataset\n",
    "    yhat = predict_dataset(X, network)\n",
    "    # round the predictions\n",
    "    yhat = [round(y) for y in yhat]\n",
    "    # calculate accuracy\n",
    "    score = accuracy_score(y, yhat)\n",
    "    return score\n",
    "\n",
    "# take a step in the search space\n",
    "def step(network, step_size):\n",
    "    new_net = list()\n",
    "    # enumerate layers in the network\n",
    "    for layer in network:\n",
    "        new_layer = list()\n",
    "        # enumerate nodes in this layer\n",
    "        for node in layer:\n",
    "            # mutate the node\n",
    "            new_node = node.copy() + randn(len(node)) * step_size\n",
    "            # store node in layer\n",
    "            new_layer.append(new_node)\n",
    "        # store layer in network\n",
    "        new_net.append(new_layer)\n",
    "    return new_net\n",
    "\n",
    "# hill climbing local search algorithm\n",
    "def hillclimbing(X, y, objective, solution, n_iter, step_size):\n",
    "    # evaluate the initial point\n",
    "    solution_eval = objective(X, y, solution)\n",
    "    # run the hill climb\n",
    "    for i in range(n_iter):\n",
    "        # take a step\n",
    "        candidate = step(solution, step_size)\n",
    "        # evaluate candidate point\n",
    "        candidte_eval = objective(X, y, candidate)\n",
    "        # check if we should keep the new point\n",
    "        if candidte_eval >= solution_eval:\n",
    "            # store the new point\n",
    "            solution, solution_eval = candidate, candidte_eval\n",
    "            # report progress\n",
    "            print('>%d %f' % (i, solution_eval))\n",
    "    return [solution, solution_eval]\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, n_informative=2, n_redundant=1, random_state=1)\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "# define the total iterations\n",
    "n_iter = 1000\n",
    "# define the maximum step size\n",
    "step_size = 0.1\n",
    "# determine the number of inputs\n",
    "n_inputs = X.shape[1]\n",
    "# one hidden layer and an output layer\n",
    "n_hidden = 10\n",
    "hidden1 = [rand(n_inputs + 1) for _ in range(n_hidden)]\n",
    "output1 = [rand(n_hidden + 1)]\n",
    "network = [hidden1, output1]\n",
    "# perform the hill climbing search\n",
    "network, score = hillclimbing(X_train, y_train, objective, network, n_iter, step_size)\n",
    "print('Done!')\n",
    "print('Best: %f' % (score))\n",
    "# generate predictions for the test dataset\n",
    "yhat = predict_dataset(X_test, network)\n",
    "# round the predictions\n",
    "yhat = [round(y) for y in yhat]\n",
    "# calculate accuracy\n",
    "score = accuracy_score(y_test, yhat)\n",
    "print('Test Accuracy: %.5f' % (score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
